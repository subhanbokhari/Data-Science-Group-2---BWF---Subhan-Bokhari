{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71d34f12-cbb2-490f-9f19-cc8cd30ca373",
   "metadata": {},
   "source": [
    "# ðŸ”´ Task 28-> Exploring Cross-Validation, Overfitting, and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2371151-6f8e-4561-bed6-924750dbeb37",
   "metadata": {},
   "source": [
    "#### The Uneven prediction or results in machine learning are due over-fitting or under-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123e429-c98c-4876-b210-b16eefcdf1a5",
   "metadata": {},
   "source": [
    "## - Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79750ce-73d1-4204-82d5-0b7a38fc9f3f",
   "metadata": {},
   "source": [
    "It is when you have a model that is not well trained and not well supervised, so it can't perform properly and cann not find patterns that are in the target data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045cc1a2-21f6-4669-9aaa-7719be352c93",
   "metadata": {},
   "source": [
    "## - Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ca2fe-cadb-4298-b5eb-8904955d9f73",
   "metadata": {},
   "source": [
    "It is when you feed the model with alot of data but along with that you also feed it unnecessary data that intervenes with the correct prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b49fafd-bfa4-4466-9dc6-68f2edcc71e4",
   "metadata": {},
   "source": [
    "## Some common techniques to address overfitting and underfitting include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4190dd-6459-45b7-9f1c-0fd4136cb422",
   "metadata": {},
   "source": [
    "ðŸŒŸ**Regularization**\n",
    "\n",
    "    Techniques like L1/L2 regularization, dropout, or early stopping that introduce a penalty for model complexity, helping to prevent the model from overfitting to the training data.\n",
    "\n",
    "ðŸŒŸ**Feature Engineering**\n",
    "\n",
    "    Adjusting the set of input features to ensure the model has the appropriate information to capture the underlying patterns in the data, avoiding both overfitting and underfitting.\n",
    "\n",
    "ðŸŒŸ**Model Selection**\n",
    "\n",
    "    Experimenting with different model architectures or hyperparameters to find the one that strikes the best balance between high performance on the training data and good generalization to the validation/test sets.\n",
    "\n",
    "ðŸŒŸ**Increasing Training Data**\n",
    "\n",
    "    Acquiring more training data can help the model learn the true patterns in the data rather than overfitting to noise or artifact, improving its ability to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1564eaac-14bf-4b62-bbd9-5356d9bf65a7",
   "metadata": {},
   "source": [
    "## -Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5faf21-4869-4d3f-b62c-e3b9547a37f8",
   "metadata": {},
   "source": [
    "Cross-validation is a technique used in machine learning to assess a model's performance and ability to generalize to new, unseen data. It involves dividing the available dataset into multiple subsets, and then training and evaluating the model on different combinations of these subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204b4dcb-75ef-4966-8354-c1b433e53cc5",
   "metadata": {},
   "source": [
    "\n",
    "The main purpose of cross-validation is to obtain a reliable estimate of the model's real-world performance, which is crucial for understanding how the model will perform in actual applications.\n",
    "\n",
    "The process typically involves the following steps:\n",
    "\n",
    "ðŸŒŸ **Data Partitioning**: The dataset is split into a number of equal-sized subsets, often referred to as \"folds\".\n",
    "\n",
    "ðŸŒŸ **Training and Evaluation**: The model is trained on all but one of the folds, and then evaluated on the remaining fold. This is repeated multiple times, with each fold serving as the evaluation set exactly once.\n",
    "\n",
    "ðŸŒŸ **Performance Estimation**: The performance metrics (e.g., accuracy, F1-score) obtained from the individual evaluations are averaged to estimate the model's overall performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
